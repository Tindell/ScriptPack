[OPENAI]
# The OpenAI model to use for generating responses
model = gpt-3.5-turbo

# Whether to print the complete response returned by the API
printResponse = True

# The operation to perform, either "generate_response" or "count_tokens"
operation = generate_response

# This is where the script will save the prompts it generates, to use for guiding later responses
saved_prompts_location=/Users/tindelllockett/projects/ScriptPack/memory/

# Whether to load prompts from the saved prompts location, to fill out the messages field in the API call
load_prompts = True

; save_prompts = False